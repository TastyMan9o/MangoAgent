from agent.utils.templates import load_template
# agent/enhancers/gemini_vision.py (å¸¦æ‘˜è¦ç‰ˆ)
# -*- coding: utf-8 -*-
import os, re, time, hashlib, subprocess, json
from pathlib import Path
from typing import Dict, Any

import google.generativeai as genai
from agent.prompt.composer_json import compose_v1_json, save_v1_json
from agent.registry.store import register_prompt
from agent.config import Settings

def _init_gemini():
    gemini_key = os.getenv("GEMINI_API_KEY")
    if not gemini_key:
        raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GEMINI_API_KEY")
    genai.configure(api_key=gemini_key)

_init_gemini()

def download_video(url: str, output_dir: str = "outputs/videos") -> Path:
    # ... æ­¤å‡½æ•°é€»è¾‘ä¸å˜ ...
    print(f"ğŸ“¥ å‡†å¤‡ä¸‹è½½è§†é¢‘: {url}")
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    bvid_match = re.search(r'(BV[a-zA-Z0-9_]+)', url)
    if not bvid_match: bvid = hashlib.md5(url.encode()).hexdigest()[:10]
    else: bvid = bvid_match.group(1)
    video_file = output_path / f"{bvid}.mp4"
    if video_file.exists() and video_file.stat().st_size > 1024 * 10:
        print(f"âœ… è§†é¢‘å·²å­˜åœ¨: {video_file}"); return video_file
    bili_cookie = os.getenv("BILI_COOKIE", "")
    command = [
        "yt-dlp", "-f", "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best", "--merge-output-format", "mp4",
        "--add-header", f"Cookie: {bili_cookie}", "--add-header", "Referer: https://www.bilibili.com/",
        "--output", str(video_file), url
    ]
    print(f"âš™ï¸ æ­£åœ¨æ‰§è¡Œä¸‹è½½å‘½ä»¤: {' '.join(command)}")
    try:
        subprocess.run(command, check=True, capture_output=True)
        print(f"âœ… è§†é¢‘ä¸‹è½½æˆåŠŸ: {video_file}"); return video_file
    except subprocess.CalledProcessError as e:
        try: error_message = e.stderr.decode('gbk')
        except UnicodeDecodeError: error_message = e.stderr.decode('utf-8', errors='ignore')
        print(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥. yt-dlp çœŸå®æŠ¥é”™:\n--- \n{error_message}\n---")
        if "ffmpeg" in error_message.lower(): print("ğŸš¨ é”™è¯¯æç¤ºä¸­åŒ…å« 'ffmpeg'ï¼Œè¯·åŠ¡å¿…ç¡®è®¤å·²æ­£ç¡®å®‰è£…å¹¶é…ç½® FFmpegã€‚")
        raise RuntimeError(f"æ— æ³•ä¸‹è½½è§†é¢‘: {url}")
    except FileNotFoundError: raise RuntimeError("æ‰¾ä¸åˆ° yt-dlp å‘½ä»¤ã€‚")

def analyze_video_and_generate_prompt(hotspot: Dict[str, Any], series: str) -> Dict[str, Any]:
    video_url = hotspot.get("url")
    if not video_url: raise ValueError("çƒ­ç‚¹æ•°æ®ç¼ºå°‘ 'url' å­—æ®µ")

    video_path = download_video(video_url)
    print(f"ğŸ§  æ­£åœ¨ä½¿ç”¨ Gemini åˆ†æè§†é¢‘: {video_path.name}...")
    model = genai.GenerativeModel('models/gemini-1.5-flash')
    video_file_obj = genai.upload_file(path=video_path)

    # --- å‡çº§ Gemini Promptï¼Œè¦æ±‚è¿”å›ä¸­æ–‡æ‘˜è¦ ---
    prompt_text = load_template("gemini_vision_system.txt", hotspot_title=hotspot.get("title", "N/A"))

    print("â³ ç­‰å¾… Gemini æ–‡ä»¶å¤„ç†å®Œæˆ..."); time.sleep(2)
    while video_file_obj.state.name == "PROCESSING":
        print('.', end='', flush=True); time.sleep(5)
        video_file_obj = genai.get_file(video_file_obj.name)

    if video_file_obj.state.name == "FAILED":
         raise ValueError(f"Gemini æ–‡ä»¶å¤„ç†å¤±è´¥: {video_file_obj.state}")
    print("\nâœ… Gemini æ–‡ä»¶å¤„ç†å®Œæˆï¼ŒçŠ¶æ€: ACTIVE")

    response = model.generate_content([prompt_text, video_file_obj], generation_config={"response_mime_type": "application/json"})
    gemini_result = json.loads(response.text)

    english_description = gemini_result.get("english_description", "No description provided.")
    chinese_title = gemini_result.get("chinese_title", "æœªå‘½åè§†é¢‘")
    video_summary = gemini_result.get("video_summary", "æ— æ‘˜è¦ä¿¡æ¯ã€‚")

    print(f"\nğŸ“ Gemini åˆ†æç»“æœ -> ä¸­æ–‡æ‘˜è¦: {video_summary}")

    s = Settings()
    prompt_obj = compose_v1_json(
        topic=english_description, series=series, defaults=s.cfg,
        source="hotspot", chinese_name=chinese_title
    )
    prompt_obj["meta"]["video_summary"] = video_summary

    saved_path = save_v1_json(prompt_obj)
    register_prompt(prompt_obj, saved_path, status="ready")
    print(f"ğŸš€ å·²æ ¹æ® Gemini åˆ†æç»“æœç”Ÿæˆ v1 Prompt: {saved_path}")

    return {"saved_path": saved_path, "prompt_content": prompt_obj, "video_summary": video_summary}