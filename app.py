# app.py (é‡æ„ç‰ˆ - è§£å†³å¯¹è¯æ¡†ä½ç½®ã€é¡µé¢æ»šåŠ¨å’Œæµå¼è¾“å‡ºé—®é¢˜)
# -*- coding: utf-8 -*-
import streamlit as st
import requests, io, time, json, pandas as pd
from datetime import datetime
import qrcode
import os

# --- App Setup ---
st.set_page_config(page_title="MangoAgent æ§åˆ¶å°", page_icon="ğŸ¤–", layout="wide")

# --- ç«¯å£è®¾ç½®åŠŸèƒ½ ---
def get_api_base_url():
    """ä»session stateè·å–APIåŸºç¡€URL"""
    port = st.session_state.get('api_port', 8001)
    return f"http://127.0.0.1:{port}"

def get_proxy_settings():
    """è·å–ä»£ç†è®¾ç½®"""
    proxy_enabled = st.session_state.get('proxy_enabled', False)
    proxy_host = st.session_state.get('proxy_host', '127.0.0.1')
    proxy_port = st.session_state.get('proxy_port', 7890)
    
    if proxy_enabled:
        return {
            "http": f"http://{proxy_host}:{proxy_port}",
            "https": f"http://{proxy_host}:{proxy_port}"
        }
    return {"http": None, "https": None}

API_BASE_URL = get_api_base_url()

# --- Reusable Functions ---
def display_prompt(prompt_content: dict):
    st.code(json.dumps(prompt_content, indent=2, ensure_ascii=False), language='json')

def refresh_prompt_list():
    try:
        resp = requests.get(f"{API_BASE_URL}/api/prompt/list", timeout=30, proxies=get_proxy_settings())
        resp.raise_for_status()
        st.session_state['prompt_files'] = resp.json()
        st.toast("Prompt åˆ—è¡¨å·²åˆ·æ–°ï¼")
    except Exception as e:
        st.error(f"è·å–Promptåˆ—è¡¨å¤±è´¥: {e}")

def format_duration(seconds: int) -> str:
    if not isinstance(seconds, (int, float)): return "N/A"
    minutes, seconds = divmod(int(seconds), 60)
    return f"{minutes:02d}:{seconds:02d}"

# --- Session State Initialization ---
for key in ['cookie_str','hotspot_results','selected_prompt','refined_result','expansion_results','iteration_result']:
    st.session_state.setdefault(key, None)
st.session_state.setdefault('prompt_files', [])
st.session_state.setdefault("agent_messages", [{"role":"assistant","content":"ä½ å¥½ï¼æˆ‘æ˜¯MangoAgentå¤§è„‘ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"}])
st.session_state.setdefault('llm_provider', "Gemini")
st.session_state.setdefault('gemini_model', "gemini-2.5-flash")
st.session_state.setdefault('deepseek_model', "deepseek-chat")
st.session_state.setdefault('show_detailed_thinking', True)  # æ–°å¢ï¼šæ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ€è€ƒè¿‡ç¨‹

# --- ä¸»é¡µé¢å¸ƒå±€ ---
st.title("ğŸ¤– MangoAgent æ§åˆ¶å°")
st.caption("æ‚¨çš„è‡ªåŠ¨åŒ–è§†é¢‘çµæ„ŸåŠ©æ‰‹")

# åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼šå·¦ä¾§åŠŸèƒ½ï¼Œå³ä¾§å¯¹è¯
left_col, right_col = st.columns([2, 1])

# --- å·¦ä¾§åŠŸèƒ½åŒºåŸŸ ---
with left_col:
    # APIå¯†é’¥ç®¡ç†
    with st.expander("ğŸ”‘ API å¯†é’¥ç®¡ç† (API Key Management)"):
        try:
            response = requests.get(f"{API_BASE_URL}/api/keys/get", proxies=get_proxy_settings())
            if response.status_code == 200:
                current_keys = response.json()
            else:
                current_keys = {}
                st.error(f"åŠ è½½APIå¯†é’¥çŠ¶æ€å¤±è´¥: {response.status_code}")
        except Exception as e:
            st.error(f"æ— æ³•è¿æ¥åç«¯åŠ è½½APIå¯†é’¥çŠ¶æ€: {e}")
            current_keys = {}
        
        # æ˜¾ç¤ºå½“å‰å¯†é’¥çŠ¶æ€
        if current_keys:
            st.info("å½“å‰å·²ä¿å­˜çš„APIå¯†é’¥çŠ¶æ€ï¼š")
            col1, col2, col3 = st.columns(3)
            with col1:
                if current_keys.get("deepseek_api_key"):
                    st.success(f"âœ… DeepSeek: å·²è®¾ç½®")
                else:
                    st.warning("âŒ DeepSeek: æœªè®¾ç½®")
            with col2:
                if current_keys.get("gemini_api_keys"):
                    key_count = len([k.strip() for k in current_keys.get("gemini_api_keys", "").split(',') if k.strip()])
                    st.success(f"âœ… Gemini: å·²è®¾ç½® ({key_count} ä¸ªå¯†é’¥)")
                else:
                    st.warning("âŒ Gemini: æœªè®¾ç½®")
            with col3:
                if current_keys.get("veo_api_key"):
                    st.success(f"âœ… Veo: å·²è®¾ç½®")
                else:
                    st.warning("âŒ Veo: æœªè®¾ç½®")
        
        with st.form("api_key_form"):
            st.info("åœ¨æ­¤å¤„è¾“å…¥æ‚¨çš„APIå¯†é’¥ï¼Œå°†è¢«å®‰å…¨åœ°å­˜å‚¨åœ¨é¡¹ç›®çš„ .env æ–‡ä»¶ä¸­ã€‚")
            deepseek_key = st.text_input("DeepSeek API Key", value=current_keys.get("deepseek_api_key", ""), type="password")
            gemini_keys_str = current_keys.get("gemini_api_keys", "")
            gemini_keys_display = "\n".join([k.strip() for k in gemini_keys_str.split(',') if k.strip()])
            gemini_keys_multiline = st.text_area("Gemini API Keys (æ¯è¡Œä¸€ä¸ªï¼Œç”¨äºè½®è¯¢)", value=gemini_keys_display, height=150, help="å½“ä¸€ä¸ªKeyè¾¾åˆ°é€Ÿç‡é™åˆ¶æ—¶ä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªã€‚æ¯è¡Œè¾“å…¥ä¸€ä¸ªAPIå¯†é’¥ã€‚")
            veo_key = st.text_input("Veo API Key", value=current_keys.get("veo_api_key", ""), type="password", help="è¾“å…¥æ‚¨çš„Veo APIå¯†é’¥")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button("ğŸ’¾ ä¿å­˜æ‰€æœ‰å¯†é’¥"):
                    with st.spinner("æ­£åœ¨ä¿å­˜..."):
                        payload = {"deepseek_api_key": deepseek_key, "veo_api_key": veo_key, "gemini_api_keys": gemini_keys_multiline}
                        try:
                            response = requests.post(f"{API_BASE_URL}/api/keys/update", json=payload, proxies=get_proxy_settings())
                            response.raise_for_status()
                            st.success("âœ… ä¿å­˜æˆåŠŸï¼é¡µé¢å°†é‡æ–°åŠ è½½ä»¥æ˜¾ç¤ºæœ€æ–°çŠ¶æ€ã€‚")
                            time.sleep(1)
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            with col2:
                if st.form_submit_button("ğŸ”„ æ¸…ç©ºè¡¨å•"):
                    st.rerun()

    # ç«¯å£è®¾ç½®
    with st.expander("âš™ï¸ ç«¯å£è®¾ç½® (Port Settings)"):
        st.info("åœ¨è¿™é‡Œé…ç½®APIç«¯å£å’Œä»£ç†è®¾ç½®ã€‚")
        
        # å…ˆå¤„ç†ä»£ç†å¯ç”¨çŠ¶æ€
        proxy_enabled = st.checkbox("å¯ç”¨ä»£ç†", value=st.session_state.get('proxy_enabled', False), help="æ˜¯å¦å¯ç”¨HTTPä»£ç†ï¼ˆVPNï¼‰")
        
        with st.form("port_settings_form"):
            col1, col2 = st.columns(2)
            with col1:
                api_port = st.number_input("APIç«¯å£", value=st.session_state.get('api_port', 8001), min_value=1024, max_value=65535, help="åç«¯APIæœåŠ¡ç«¯å£ï¼ˆä¸æ˜¯VPNç«¯å£ï¼‰")
            with col2:
                # æ˜¾ç¤ºå½“å‰ä»£ç†çŠ¶æ€
                if proxy_enabled:
                    st.success("âœ… ä»£ç†å·²å¯ç”¨")
                else:
                    st.info("âŒ ä»£ç†æœªå¯ç”¨")
            
            # ä»£ç†è®¾ç½®éƒ¨åˆ†
            if proxy_enabled:
                st.markdown("**ä»£ç†è®¾ç½®ï¼š**")
                col3, col4 = st.columns(2)
                with col3:
                    proxy_host = st.text_input("ä»£ç†ä¸»æœº", value=st.session_state.get('proxy_host', '127.0.0.1'), help="ä»£ç†æœåŠ¡å™¨åœ°å€ï¼ˆé€šå¸¸æ˜¯127.0.0.1ï¼‰")
                with col4:
                    proxy_port = st.number_input("ä»£ç†ç«¯å£", value=st.session_state.get('proxy_port', 7890), min_value=1024, max_value=65535, help="VPNä»£ç†ç«¯å£ï¼ˆå¦‚7890ã€1080ç­‰ï¼‰")
            else:
                proxy_host = st.session_state.get('proxy_host', '127.0.0.1')
                proxy_port = st.session_state.get('proxy_port', 7890)
            
            if st.form_submit_button("ä¿å­˜ç«¯å£è®¾ç½®"):
                st.session_state['api_port'] = api_port
                st.session_state['proxy_enabled'] = proxy_enabled
                if proxy_enabled:
                    st.session_state['proxy_host'] = proxy_host
                    st.session_state['proxy_port'] = proxy_port
                st.success("ç«¯å£è®¾ç½®å·²ä¿å­˜ï¼é¡µé¢å°†é‡æ–°åŠ è½½ä»¥åº”ç”¨æ–°è®¾ç½®ã€‚")
                time.sleep(1)
                st.rerun()

    # åˆ·æ–°Promptåˆ—è¡¨
    if not st.session_state['prompt_files']:
        refresh_prompt_list()

    # åŠŸèƒ½æ ‡ç­¾é¡µ
    tab_login, tab_manage, tab_hotspot, tab_iterate, tab_refine, tab_expand, tab_generate = st.tabs(
        ["ğŸ”‘ æˆæƒç™»å½•", "ğŸ—‚ï¸ Prompt ç®¡ç†", "ğŸ”¥ çƒ­ç‚¹å‘ç° & ç”Ÿæˆ", "ğŸ” å•è§†é¢‘è¿­ä»£", "âœï¸ äº¤äº’å¼ä¼˜åŒ–", "ğŸ’¡ åˆ›æ„æ‰©å±•", "ğŸ¬ è§†é¢‘ç”Ÿæˆ"])

    # æˆæƒç™»å½•æ ‡ç­¾é¡µ
    with tab_login:
        st.header("Bilibili æˆæƒç™»å½•")
        if st.session_state.get('cookie_str'):
            st.success("ğŸ‰ æ‚¨å·²ç™»å½•æˆåŠŸï¼")
        else:
            st.info("ä¸ºäº†ä½¿ç”¨Bç«™ç›¸å…³åŠŸèƒ½ï¼Œè¯·å…ˆæˆæƒç™»å½•ã€‚")
            if st.button("1. è·å–Bç«™ç™»å½•äºŒç»´ç "):
                try:
                    with st.spinner("è¯·æ±‚äºŒç»´ç ..."):
                        response = requests.get(f"{API_BASE_URL}/api/auth/get-qr-code", proxies=get_proxy_settings())
                        response.raise_for_status()
                        data = response.json()
                        st.session_state['qrcode_key'] = data.get("qrcode_key")
                        login_url = data.get("url")
                    qr = qrcode.QRCode(box_size=10, border=4)
                    qr.add_data(login_url)
                    img = qr.make_image(fill_color="black", back_color="white")
                    buf = io.BytesIO()
                    img.save(buf, format='PNG')
                    st.image(buf.getvalue(), caption="è¯·åœ¨ 2 åˆ†é’Ÿå†…ä½¿ç”¨æ‰‹æœºBç«™APPæ‰«æ", width=250)
                    st.session_state['login_active'] = True
                except Exception as e:
                    st.error(f"è¿æ¥åç«¯æœåŠ¡å¤±è´¥: {e}")
            if st.session_state.get('login_active', False):
                status_placeholder = st.empty()
                status_placeholder.info("â³ ç­‰å¾…æ‰«ç ...")
                for i in range(60):
                    try:
                        poll_resp = requests.get(f"{API_BASE_URL}/api/auth/poll-qr-code", params={"qrcode_key": st.session_state['qrcode_key']}, proxies=get_proxy_settings())
                        poll_data = poll_resp.json()
                        code = poll_data.get("code")
                        if code == 86090: status_placeholder.info("ğŸ‘ å·²æ‰«ç ...")
                        elif code == 0:
                            st.session_state['cookie_str'] = poll_data.get("cookie_str")
                            st.session_state['login_active'] = False
                            status_placeholder.success("âœ… ç™»å½•æˆåŠŸï¼é¡µé¢å³å°†åˆ·æ–°...")
                            time.sleep(2)
                            st.rerun()
                            break
                        elif code == 86038:
                            status_placeholder.error("âŒ äºŒç»´ç å·²è¿‡æœŸã€‚")
                            st.session_state['login_active'] = False
                            break
                        time.sleep(2)
                    except:
                        st.session_state['login_active'] = False
                        break

    # Promptç®¡ç†æ ‡ç­¾é¡µ
    with tab_manage:
        st.header("ğŸ—‚ï¸ Prompt ç®¡ç†")
        st.markdown("åœ¨è¿™é‡Œæ‚¨å¯ä»¥æŸ¥çœ‹ã€æœç´¢å’Œåˆ é™¤æ‰€æœ‰å·²ç”Ÿæˆçš„Promptã€‚")
        if st.button("ğŸ”„ åˆ·æ–°Promptåˆ—è¡¨", key="refresh_btn_manage"):
            refresh_prompt_list()
            st.rerun()
        if not st.session_state.get('prompt_files', []):
            st.info("å½“å‰æ²¡æœ‰å¯ç®¡ç†çš„Promptã€‚")
        else:
            search_term = st.text_input("æœç´¢Promptæ–‡ä»¶å", placeholder="è¾“å…¥å…³é”®è¯è¿‡æ»¤...", key="manage_search")
            filtered_prompts = [p for p in st.session_state['prompt_files'] if search_term.lower() in p.lower()]
            if not filtered_prompts:
                st.warning("æœªæ‰¾åˆ°åŒ¹é…çš„Promptã€‚")
            else:
                prompts_df = pd.DataFrame({"path": filtered_prompts})
                prompts_df["filename"] = prompts_df["path"].apply(os.path.basename)
                prompts_df["delete"] = False
                st.info("å‹¾é€‰æ‚¨æƒ³åˆ é™¤çš„Promptï¼Œç„¶åç‚¹å‡»ä¸‹æ–¹çš„åˆ é™¤æŒ‰é’®ã€‚")
                edited_df = st.data_editor(
                    prompts_df[["delete", "filename"]],
                    column_config={"delete": st.column_config.CheckboxColumn("åˆ é™¤?", default=False),"filename": st.column_config.TextColumn("Prompt æ–‡ä»¶å"),},
                    use_container_width=True,
                    hide_index=True,
                    key="manage_data_editor"
                )
                prompts_to_delete = edited_df[edited_df["delete"]]
                if not prompts_to_delete.empty:
                    if st.button(f"ğŸ—‘ï¸ ç¡®è®¤åˆ é™¤é€‰ä¸­çš„ {len(prompts_to_delete)} ä¸ªPrompt", type="primary", key="confirm_delete_btn"):
                        deleted_count = 0
                        error_count = 0
                        progress_bar = st.progress(0, text="å¼€å§‹åˆ é™¤...")
                        merged_df = prompts_df.merge(prompts_to_delete, on="filename", how="inner")
                        for i, row in enumerate(merged_df.itertuples()):
                            full_path = row.path
                            filename = row.filename
                            progress_text = f"æ­£åœ¨åˆ é™¤ ({i+1}/{len(merged_df)}): {filename}..."
                            progress_bar.progress((i + 1) / len(merged_df), text=progress_text)
                            try:
                                payload = {"prompt_path": full_path}
                                response = requests.delete(f"{API_BASE_URL}/api/prompt/delete", json=payload, proxies=get_proxy_settings())
                                response.raise_for_status()
                                deleted_count += 1
                            except Exception as e:
                                st.error(f"åˆ é™¤ '{filename}' å¤±è´¥: {e}")
                                error_count += 1
                        progress_bar.empty()
                        st.success(f"æ“ä½œå®Œæˆï¼æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªPromptã€‚")
                        if error_count > 0:
                            st.error(f"{error_count} ä¸ªPromptåˆ é™¤å¤±è´¥ã€‚")
                        time.sleep(1)
                        refresh_prompt_list()
                        st.rerun()

    # çƒ­ç‚¹å‘ç°æ ‡ç­¾é¡µ
    with tab_hotspot:
        st.header("ğŸ”¥ çƒ­ç‚¹å‘ç° & ç”Ÿæˆ")
        st.button("ğŸ”„ åˆ·æ–°Promptåˆ—è¡¨", on_click=refresh_prompt_list, key="refresh_btn_hotspot")
        if not st.session_state.get('cookie_str'):
            st.warning("è¯·å…ˆåœ¨'æˆæƒç™»å½•'æ ‡ç­¾é¡µå®Œæˆç™»å½•ã€‚")
        else:
            with st.expander("âš™ï¸ è°ƒæ•´æ’åºç®—æ³•æƒé‡"):
                weights = {}
                c1, c2, c3 = st.columns(3)
                with c1:
                    weights['likes'] = st.slider("ğŸ‘ ç‚¹èµ", 0.0, 2.0, 1.0, 0.05, key="w_likes")
                    weights['comments'] = st.slider("ğŸ’¬ è¯„è®º", 0.0, 2.0, 0.8, 0.05, key="w_comments")
                with c2:
                    weights['danmaku'] = st.slider("ğŸï¸ å¼¹å¹•", 0.0, 2.0, 0.5, 0.05, key="w_danmaku")
                    weights['gravity'] = st.slider("â³ æ—¶é—´è¡°å‡å› å­", 1.0, 2.5, 1.8, 0.05, key="w_gravity")
                with c3:
                    weights['duration_weight'] = st.slider("â±ï¸ æ—¶é•¿æƒ©ç½š (å€¼è¶Šé«˜è¶Šåçˆ±çŸ­è§†é¢‘)", 0.0, 1.0, 0.25, 0.05, key="w_duration")
                weights['views'] = 0.1
            c1, c2 = st.columns([2, 1])
            with c1:
                keywords_input = st.text_input("æœç´¢å…³é”®è¯ (ç”¨é€—å·åˆ†éš”)", placeholder="ä¾‹å¦‚: ç§‘æŠ€, AI, æ¸¸æˆ...", key="hotspot_keywords")
                if st.button("ğŸ” æœç´¢çƒ­ç‚¹è§†é¢‘"):
                    with st.spinner("æ­£åœ¨æœç´¢Bç«™çƒ­ç‚¹è§†é¢‘..."):
                        response = requests.post(f"{API_BASE_URL}/api/hotspot/search", json={"keywords": [k.strip() for k in keywords_input.split(",")], "weights": weights}, proxies=get_proxy_settings())
                        if response.status_code == 200: st.session_state['hotspot_results'] = response.json()
                        else: st.error(f"æœç´¢å¤±è´¥: {response.text}")
            with c2:
                manual_url = st.text_input("æˆ–ç›´æ¥è¾“å…¥Bç«™è§†é¢‘URL", key="manual_url_hotspot")
                if st.button("ğŸ¯ ç›´æ¥åˆ†ææ­¤é“¾æ¥"):
                    with st.spinner("æ­£åœ¨å¤„ç†æ‰‹åŠ¨é“¾æ¥..."):
                        try:
                            response = requests.post(f"{API_BASE_URL}/api/hotspot/generate-from-link", json={"video_url": manual_url}, proxies=get_proxy_settings())
                            response.raise_for_status()
                            result_data = response.json()
                            st.success("åˆ†æå®Œæˆï¼")
                            for res in result_data.get("results", []):
                                st.subheader(f"ç”Ÿæˆç»“æœ: `{res.get('saved_path')}`")
                                st.info(f"ğŸ¤– **Gemini è§†é¢‘æ‘˜è¦**: {res.get('video_summary')}")
                                display_prompt(res.get("prompt_content"))
                        except Exception as e:
                            st.error(f"å¤„ç†é“¾æ¥å¤±è´¥: {e}")
            if st.session_state.get('hotspot_results'):
                st.subheader("æœç´¢ç»“æœ")
                df = pd.DataFrame(st.session_state['hotspot_results'])
                df['pubdate_str'] = pd.to_datetime(df['pubdate'], unit='s', errors='coerce').dt.strftime('%Y-%m-%d %H:%M')
                df['duration_str'] = df['duration'].apply(format_duration)
                df['likes'] = df['stats'].apply(lambda x: x.get('likes', 0))
                df['comments'] = df['stats'].apply(lambda x: x.get('comments', 0))
                display_cols = {'title': 'ğŸ¬ æ ‡é¢˜', 'score': 'ğŸ”¥ çƒ­åº¦åˆ†', 'likes': 'ğŸ‘ ç‚¹èµ', 'comments': 'ğŸ’¬ è¯„è®º', 'duration_str': 'â±ï¸ æ—¶é•¿', 'pubdate_str': 'ğŸ“… å‘å¸ƒæ—¶é—´', 'url': 'ğŸ”— é“¾æ¥'}
                df_display = df[list(display_cols.keys())].rename(columns=display_cols)
                df_display['select'] = False
                column_config = {"ğŸ”— é“¾æ¥": st.column_config.LinkColumn("è§†é¢‘é“¾æ¥", display_text="è·³è½¬")}
                edited_df = st.data_editor(df_display, hide_index=True, column_order=('select', 'ğŸ¬ æ ‡é¢˜', 'ğŸ”¥ çƒ­åº¦åˆ†', 'â±ï¸ æ—¶é•¿', 'ğŸ‘ ç‚¹èµ', 'ğŸ’¬ è¯„è®º', 'ğŸ“… å‘å¸ƒæ—¶é—´', 'ğŸ”— é“¾æ¥'), column_config=column_config, height=350, use_container_width=True)
                selected_rows = edited_df[edited_df.select]
                if not selected_rows.empty:
                    st.write("å·²é€‰æ‹©çš„çƒ­ç‚¹:")
                    st.dataframe(selected_rows[['ğŸ¬ æ ‡é¢˜', 'ğŸ”¥ çƒ­åº¦åˆ†']], hide_index=True, use_container_width=True)
                    if st.button("ğŸ§  å¯¹æ‰€é€‰é¡¹è¿›è¡ŒGeminiåˆ†æ"):
                        with st.spinner("æ­£åœ¨ä¸‹è½½è§†é¢‘å¹¶è¿›è¡ŒGeminiåˆ†æ..."):
                            selected_urls = selected_rows['ğŸ”— é“¾æ¥'].tolist()
                            hotspots_to_process = [h for h in st.session_state['hotspot_results'] if h['url'] in selected_urls]
                            for hotspot in hotspots_to_process:
                                try:
                                    res = requests.post(f"{API_BASE_URL}/api/hotspot/generate-from-link", json={"video_url": hotspot['url']}, proxies=get_proxy_settings()).json()
                                    for r in res.get("results", []):
                                        st.subheader(f"ç”Ÿæˆç»“æœ: `{r.get('saved_path')}`")
                                        st.info(f"ğŸ¤– **Gemini è§†é¢‘æ‘˜è¦**: {r.get('video_summary')}")
                                        display_prompt(r.get("prompt_content"))
                                except Exception as e:
                                    st.error(f"åˆ†æ {hotspot['title']} å¤±è´¥: {e}")

    # å…¶ä»–æ ‡ç­¾é¡µï¼ˆç®€åŒ–ç‰ˆï¼‰
    # è·å–å¯ç”¨çš„Prompté€‰é¡¹
    prompt_options = st.session_state.get('prompt_files', [])
    
    with tab_iterate:
        st.header("ğŸ” å•è§†é¢‘è¿­ä»£")
        st.markdown("åŸºäºç°æœ‰Promptå’Œè§†é¢‘URLè¿›è¡Œè¿­ä»£ä¼˜åŒ–")
        
        col1, col2 = st.columns(2)
        with col1:
            base_prompt = st.selectbox("é€‰æ‹©åŸºç¡€Prompt", prompt_options, key="iterate_base")
            video_url = st.text_input("è¾“å…¥è§†é¢‘URL", placeholder="https://www.bilibili.com/video/BV...", key="iterate_url")
        
        with col2:
            max_comments = st.number_input("æœ€å¤§è¯„è®ºæ•°", min_value=50, max_value=500, value=200, key="iterate_comments")
            top_deltas = st.number_input("é‡‡çº³å»ºè®®æ•°", min_value=1, max_value=10, value=3, key="iterate_deltas")
        
        if st.button("ğŸš€ å¼€å§‹è¿­ä»£", key="iterate_btn"):
            if base_prompt and video_url:
                try:
                    with st.spinner("æ­£åœ¨è¿­ä»£ä¸­..."):
                        response = requests.post(f"{API_BASE_URL}/api/iterate/from-video", 
                                              json={"base_prompt_path": base_prompt, "video_url": video_url},
                                              proxies=get_proxy_settings())
                        if response.status_code == 200:
                            result = response.json()
                            st.success(f"è¿­ä»£å®Œæˆï¼æ–°ç‰ˆæœ¬: {result.get('new_prompt_path', 'N/A')}")
                            if result.get('report_path'):
                                st.info(f"è¯¦ç»†æŠ¥å‘Š: {result.get('report_path')}")
                        else:
                            st.error(f"è¿­ä»£å¤±è´¥: {response.text}")
                except Exception as e:
                    st.error(f"è¿­ä»£å‡ºé”™: {e}")
            else:
                st.warning("è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")

    with tab_refine:
        st.header("âœï¸ äº¤äº’å¼ä¼˜åŒ–")
        st.markdown("åŸºäºç”¨æˆ·åé¦ˆä¼˜åŒ–ç°æœ‰Prompt")
        
        col1, col2 = st.columns(2)
        with col1:
            refine_prompt = st.selectbox("é€‰æ‹©è¦ä¼˜åŒ–çš„Prompt", prompt_options, key="refine_prompt")
            feedback = st.text_area("è¾“å…¥ä¼˜åŒ–å»ºè®®", placeholder="ä¾‹å¦‚ï¼šè®©å®ƒæ›´æ¸©é¦¨ä¸€äº›ï¼Œå¢åŠ ä¸€äº›æš–è‰²è°ƒ...", key="refine_feedback")
        
        with col2:
            model_choice = st.selectbox("é€‰æ‹©ä¼˜åŒ–æ¨¡å‹", ["deepseek-chat", "deepseek-reasoner"], key="refine_model")
        
        if st.button("ğŸ”§ å¼€å§‹ä¼˜åŒ–", key="refine_btn"):
            if refine_prompt and feedback:
                try:
                    with st.spinner("æ­£åœ¨ä¼˜åŒ–ä¸­..."):
                        response = requests.post(f"{API_BASE_URL}/api/prompt/refine", 
                                              json={"prompt_path": refine_prompt, "feedback": feedback},
                                              proxies=get_proxy_settings())
                        if response.status_code == 200:
                            result = response.json()
                            st.success(f"ä¼˜åŒ–å®Œæˆï¼æ–°ç‰ˆæœ¬: {result.get('new_prompt_path', 'N/A')}")
                        else:
                            st.error(f"ä¼˜åŒ–å¤±è´¥: {response.text}")
                except Exception as e:
                    st.error(f"ä¼˜åŒ–å‡ºé”™: {e}")
            else:
                st.warning("è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")

    with tab_expand:
        st.header("ğŸ’¡ åˆ›æ„æ‰©å±•")
        st.markdown("åŸºäºç°æœ‰Promptç”Ÿæˆåˆ›æ„å˜ä½“")
        
        col1, col2 = st.columns(2)
        with col1:
            expand_prompt = st.selectbox("é€‰æ‹©åŸºç¡€Prompt", prompt_options, key="expand_prompt")
            num_expansions = st.number_input("æ‰©å±•æ•°é‡", min_value=1, max_value=10, value=3, key="expand_num")
        
        with col2:
            user_hint = st.text_input("åˆ›æ„æç¤ºï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šæ›´æ¢¦å¹»çš„é£æ ¼", key="expand_hint")
        
        if st.button("âœ¨ å¼€å§‹æ‰©å±•", key="expand_btn"):
            if expand_prompt:
                try:
                    with st.spinner("æ­£åœ¨æ‰©å±•ä¸­..."):
                        payload = {"prompt_path": expand_prompt, "num_expansions": num_expansions}
                        if user_hint:
                            payload["user_hint"] = user_hint
                        
                        response = requests.post(f"{API_BASE_URL}/api/prompt/expand", 
                                              json=payload,
                                              proxies=get_proxy_settings())
                        if response.status_code == 200:
                            result = response.json()
                            st.success(f"æ‰©å±•å®Œæˆï¼ç”Ÿæˆäº† {len(result.get('generated_prompts', []))} ä¸ªå˜ä½“")
                            for i, prompt in enumerate(result.get('generated_prompts', [])):
                                st.info(f"å˜ä½“ {i+1}: {prompt.get('saved_path', 'N/A')}")
                        else:
                            st.error(f"æ‰©å±•å¤±è´¥: {response.text}")
                except Exception as e:
                    st.error(f"æ‰©å±•å‡ºé”™: {e}")
            else:
                st.warning("è¯·é€‰æ‹©åŸºç¡€Prompt")

    with tab_generate:
        st.header("ğŸ¬ è§†é¢‘ç”Ÿæˆ")
        st.markdown("ä½¿ç”¨Flowæˆ–Veoç”Ÿæˆè§†é¢‘")
        
        col1, col2 = st.columns(2)
        with col1:
            generation_method = st.selectbox("ç”Ÿæˆæ–¹å¼", ["Flow (æµè§ˆå™¨è‡ªåŠ¨åŒ–)", "Veo 3 API"], key="generate_method")
            
            # æ ¹æ®ç”Ÿæˆæ–¹å¼é€‰æ‹©prompté€‰æ‹©å™¨
            if generation_method == "Flow (æµè§ˆå™¨è‡ªåŠ¨åŒ–)":
                generate_prompt = st.multiselect("é€‰æ‹©Promptï¼ˆå¯å¤šé€‰ï¼‰", prompt_options, key="generate_prompt_multiselect")
            else:
                generate_prompt = st.selectbox("é€‰æ‹©Prompt", prompt_options, key="generate_prompt_single")
        
        with col2:
            if generation_method == "Flow (æµè§ˆå™¨è‡ªåŠ¨åŒ–)":
                flow_url = st.text_input("Flowé¡µé¢URLï¼ˆå¯é€‰ï¼‰", placeholder="https://labs.google.com/flow/...", key="flow_url")
                debug_port = st.number_input("è°ƒè¯•ç«¯å£", min_value=9222, max_value=9230, value=9222, key="debug_port")
            else:
                st.info("Veo 3 APIç”Ÿæˆ")
        
        if st.button("ğŸ¬ å¼€å§‹ç”Ÿæˆ", key="generate_btn"):
            # æ ¹æ®ç”Ÿæˆæ–¹å¼è·å–é€‰ä¸­çš„prompt
            if generation_method == "Flow (æµè§ˆå™¨è‡ªåŠ¨åŒ–)":
                selected_prompts = st.session_state.get("generate_prompt_multiselect", [])
            else:
                selected_prompts = [st.session_state.get("generate_prompt_single")]
            
            if selected_prompts and any(selected_prompts):
                try:
                    with st.spinner("æ­£åœ¨ç”Ÿæˆä¸­..."):
                        if generation_method == "Flow (æµè§ˆå™¨è‡ªåŠ¨åŒ–)":
                            payload = {"prompt_paths": selected_prompts}
                            if flow_url:
                                payload["flow_url"] = flow_url
                            payload["debugging_port"] = debug_port
                            
                            response = requests.post(f"{API_BASE_URL}/api/generate/video", 
                                                  json=payload,
                                                  proxies=get_proxy_settings())
                        else:
                            # Veo API ä»ç„¶åªæ”¯æŒå•ä¸ªprompt
                            response = requests.post(f"{API_BASE_URL}/api/generate/veo", 
                                                  json={"prompt_path": selected_prompts[0]},
                                                  proxies=get_proxy_settings())
                        
                        if response.status_code == 200:
                            result = response.json()
                            if generation_method == "Flow (æµè§ˆå™¨è‡ªåŠ¨åŒ–)":
                                # å¤„ç†å¤šä¸ªpromptçš„ç»“æœ
                                if "results" in result:
                                    st.success(f"æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²æäº¤ï¼æ€»è®¡: {result.get('total', 0)} ä¸ª")
                                    st.info(f"æˆåŠŸ: {result.get('successful', 0)} ä¸ª, å¤±è´¥: {result.get('failed', 0)} ä¸ª")
                                    
                                    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                                    for i, res in enumerate(result.get('results', [])):
                                        if res.get('success'):
                                            st.success(f"âœ… {res.get('prompt_path', 'N/A')}: {res.get('message', 'æˆåŠŸ')}")
                                        else:
                                            st.error(f"âŒ {res.get('prompt_path', 'N/A')}: {res.get('error', 'å¤±è´¥')}")
                                else:
                                    st.success(f"ç”Ÿæˆä»»åŠ¡å·²æäº¤ï¼{result.get('message', '')}")
                            else:
                                st.success(f"ç”Ÿæˆä»»åŠ¡å·²æäº¤ï¼{result.get('message', '')}")
                            
                            if result.get('task_id'):
                                st.info(f"ä»»åŠ¡ID: {result.get('task_id')}")
                        else:
                            st.error(f"ç”Ÿæˆå¤±è´¥: {response.text}")
                except Exception as e:
                    st.error(f"ç”Ÿæˆå‡ºé”™: {e}")
            else:
                st.warning("è¯·é€‰æ‹©Prompt")

# --- å³ä¾§å¯¹è¯åŒºåŸŸ ---
with right_col:
    st.header("ğŸ§  AI åŠ©æ‰‹")
    
    # å¤§è„‘è®¾ç½®
    with st.expander("âš™ï¸ å¤§è„‘è®¾ç½®", expanded=True):
        st.selectbox("é€‰æ‹©å¤§æ¨¡å‹ä¾›åº”å•†", ["Gemini","DeepSeek"], key='llm_provider')
        if st.session_state.llm_provider == "Gemini":
            st.selectbox("é€‰æ‹©å…·ä½“æ¨¡å‹ (Gemini)", ["gemini-2.5-flash","gemini-2.5-pro"], key='gemini_model')
            model_name = st.session_state.gemini_model
        else:
            st.selectbox("é€‰æ‹©å…·ä½“æ¨¡å‹ (DeepSeek)", ["deepseek-chat","deepseek-reasoner"], key='deepseek_model')
            model_name = st.session_state.deepseek_model
        st.info(f"å½“å‰å¤§è„‘: **{st.session_state.llm_provider} ({model_name})**")
        
        # æµå¼è¾“å‡ºè®¾ç½®
        st.markdown("##### æµå¼è¾“å‡ºè®¾ç½®")
        show_detailed = st.checkbox("æ˜¾ç¤ºè¯¦ç»†æ€è€ƒè¿‡ç¨‹", value=st.session_state.show_detailed_thinking, 
                                   help="å¯ç”¨åå°†å®æ—¶æ˜¾ç¤ºAIçš„æ€è€ƒè¿‡ç¨‹å’Œå·¥å…·è°ƒç”¨")
        st.session_state.show_detailed_thinking = show_detailed

    # å¯¹è¯å†å²
    st.markdown("##### ğŸ’¬ å¯¹è¯å†å²")
    
    # åˆ›å»ºå¯æ»šåŠ¨çš„å¯¹è¯å®¹å™¨
    chat_container = st.container()
    
    with chat_container:
        # æ˜¾ç¤ºæ‰€æœ‰å¯¹è¯æ¶ˆæ¯
        for i, message in enumerate(st.session_state.agent_messages):
            with st.chat_message(message["role"]):
                st.markdown(message.get("content",""))
        
        # æ·»åŠ è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨çš„JavaScript
        if st.session_state.agent_messages:
            st.markdown("""
            <script>
            // è‡ªåŠ¨æ»šåŠ¨åˆ°å¯¹è¯åº•éƒ¨
            window.scrollTo(0, document.body.scrollHeight);
            </script>
            """, unsafe_allow_html=True)

    # è¾“å…¥æ¡†
    if prompt := st.chat_input("ä¾‹å¦‚: å¸®æˆ‘æŠŠè¿™ä¸¤ä¸ªpromptéƒ½ç”¨æµè§ˆå™¨ç”Ÿæˆè§†é¢‘"):
        st.session_state.agent_messages.append({"role": "user", "content": prompt})
        
        # åˆ›å»ºå¯¹è¯æ¶ˆæ¯
        with st.chat_message("assistant"):
            # åˆ›å»ºå¤šä¸ªå ä½ç¬¦ç”¨äºä¸åŒç±»å‹çš„è¾“å‡º
            message_placeholder = st.empty()
            thinking_placeholder = st.empty()
            tool_placeholder = st.empty()
            full_response = ""
            
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            cleaned_msgs = [{"role": m.get("role","user"), "content": m.get("content","")} for m in st.session_state.agent_messages]
            payload = {"messages": cleaned_msgs, "llm_provider": st.session_state.llm_provider, "model_name": model_name}
            
            try:
                with requests.post(f"{API_BASE_URL}/api/agent/chat_stream", json=payload, stream=True, timeout=None, proxies=get_proxy_settings()) as r:
                    r.raise_for_status()
                    
                    # æ ¹æ®è®¾ç½®å†³å®šæ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ€è€ƒè¿‡ç¨‹
                    if st.session_state.show_detailed_thinking:
                        # æ˜¾ç¤ºåˆå§‹æ€è€ƒçŠ¶æ€
                        thinking_placeholder.info("ğŸ¤” AIæ­£åœ¨æ€è€ƒä¸­...")
                    
                    for line in r.iter_lines():
                        if line:
                            decoded_line = line.decode('utf-8')
                            if decoded_line.startswith('data:'):
                                try:
                                    event_data = json.loads(decoded_line[5:])
                                    event_type = event_data.get("type")
                                    
                                    if event_type == "thinking_start":
                                        # æ˜¾ç¤ºå¼€å§‹æ€è€ƒ
                                        if st.session_state.show_detailed_thinking:
                                            thinking_placeholder.info("ğŸ¤” AIæ­£åœ¨åˆ†ææ‚¨çš„è¯·æ±‚...")
                                        
                                    elif event_type == "thought":
                                        # æ¸…é™¤æ€è€ƒçŠ¶æ€ï¼Œæ˜¾ç¤ºå®é™…æ€è€ƒå†…å®¹
                                        if st.session_state.show_detailed_thinking:
                                            thinking_placeholder.empty()
                                        content = event_data.get("content", "")
                                        full_response += content
                                        message_placeholder.markdown(full_response + "â–Œ")
                                        
                                    elif event_type == "tool_start":
                                        tool_name = event_data.get('tool_name')
                                        tool_args = event_data.get('tool_args', {})
                                        
                                        if st.session_state.show_detailed_thinking:
                                            # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                                            tool_info = f"""
                                            **ğŸ› ï¸ æ­£åœ¨è°ƒç”¨å·¥å…·:** `{tool_name}`
                                            
                                            **å‚æ•°:** `{json.dumps(tool_args, indent=2, ensure_ascii=False)}`
                                            """
                                            tool_placeholder.info(tool_info)
                                        
                                        # åœ¨æ€è€ƒå†…å®¹ä¸­æ·»åŠ å·¥å…·è°ƒç”¨è®°å½•
                                        full_response += f"\n\n**ğŸ› ï¸ è°ƒç”¨å·¥å…·:** `{tool_name}`\n\n"
                                        message_placeholder.markdown(full_response + "â–Œ")
                                        
                                    elif event_type == "tool_end":
                                        tool_name = event_data.get('tool_name')
                                        tool_output = event_data.get('output', "")
                                        
                                        if st.session_state.show_detailed_thinking:
                                            # æ¸…é™¤å·¥å…·è°ƒç”¨ä¿¡æ¯
                                            tool_placeholder.empty()
                                        
                                        # æ ¼å¼åŒ–å·¥å…·è¾“å‡º - æ˜¾ç¤ºå®Œæ•´å†…å®¹
                                        if isinstance(tool_output, dict):
                                            # å¦‚æœæ˜¯å­—å…¸ï¼Œæ˜¾ç¤ºå…³é”®ä¿¡æ¯
                                            if 'success' in tool_output:
                                                status_icon = "âœ…" if tool_output['success'] else "âŒ"
                                                tool_output_display = f"{status_icon} {tool_output.get('message', '')}"
                                                if 'task_id' in tool_output:
                                                    tool_output_display += f"\nä»»åŠ¡ID: {tool_output['task_id']}"
                                                if 'prompt_path' in tool_output:
                                                    tool_output_display += f"\næ–‡ä»¶è·¯å¾„: {tool_output['prompt_path']}"
                                            else:
                                                tool_output_display = json.dumps(tool_output, indent=2, ensure_ascii=False)
                                        elif isinstance(tool_output, str):
                                            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼ˆä¸æˆªæ–­ï¼‰
                                            tool_output_display = tool_output
                                        else:
                                            tool_output_display = str(tool_output)
                                        
                                        # åœ¨æ€è€ƒå†…å®¹ä¸­æ·»åŠ å·¥å…·è¿”å›è®°å½•
                                        full_response += f"**âœ… å·¥å…·è¿”å›:**\n```\n{tool_output_display}\n```\n\n"
                                        message_placeholder.markdown(full_response + "â–Œ")
                                        
                                    elif event_type == "thinking_end":
                                        # æ˜¾ç¤ºæ€è€ƒå®Œæˆ
                                        if st.session_state.show_detailed_thinking:
                                            thinking_placeholder.success("âœ… åˆ†æå®Œæˆï¼")
                                        
                                    elif event_type == "error":
                                        error_content = event_data.get('content', "æœªçŸ¥é”™è¯¯")
                                        full_response += f"\n\n**âŒ é”™è¯¯**: {error_content}"
                                        if st.session_state.show_detailed_thinking:
                                            thinking_placeholder.error(f"âŒ å‘ç”Ÿé”™è¯¯: {error_content}")
                                        break
                                        
                                    elif event_type == "done":
                                        if st.session_state.show_detailed_thinking:
                                            thinking_placeholder.success("âœ… ä»»åŠ¡å®Œæˆï¼")
                                        break
                                        
                                except json.JSONDecodeError:
                                    pass
                    
                    # æœ€ç»ˆæ˜¾ç¤ºå®Œæ•´å“åº”
                    message_placeholder.markdown(full_response)
                    st.session_state.agent_messages.append({"role": "assistant", "content": full_response})
                    
                    # è‡ªåŠ¨æ»šåŠ¨åˆ°å¯¹è¯åº•éƒ¨
                    st.experimental_rerun()
                    
            except requests.exceptions.RequestException as e:
                if st.session_state.show_detailed_thinking:
                    thinking_placeholder.error(f"âŒ è¿æ¥åç«¯æµå¼æ¥å£å¤±è´¥: {e}")
                st.error(f"è¿æ¥åç«¯æµå¼æ¥å£å¤±è´¥: {e}")

# --- é¡µé¢åº•éƒ¨ ---
st.markdown("---")
st.markdown("### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("APIçŠ¶æ€", "ğŸŸ¢ æ­£å¸¸" if requests.get(f"{API_BASE_URL}/api/health", proxies=get_proxy_settings()).status_code == 200 else "ğŸ”´ å¼‚å¸¸")
with col2:
    st.metric("Promptæ•°é‡", len(st.session_state.get('prompt_files', [])))
with col3:
    st.metric("å¯¹è¯æ¶ˆæ¯", len(st.session_state.get('agent_messages', [])))
